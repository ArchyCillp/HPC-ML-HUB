---
title: 5. Performance Guidelines
---

### 5.1 Overall Performance Optimization Strategies
- 优化讲的是四个基本策略
	- 最大化并行度 以最大化利用好资源
	- 优化内存使用 以最大化内存吞吐量
	- 优化指令使用 以最大化指令吞吐量
	- 减少内存抖动（虚拟内存交换）
- 优化的方向取决于性能瓶颈
	- memory-bound优化指令使用不会带来显著的性能提升
	- 通过profiler看FLOPS和memory吞吐量达到了峰值的多少

### 5.2 Maximize Utilization
- 应用层面
	- 并行的工作给GPU
	- 串行的工作给CPU
	- 用stream和异步操作使host和device能并行工作
	- 数据交流应该尽可能发生在block内部，减少global数据的交流
- multiprocessor层面
	- 指令执行机制
		- 每个multiprocessor有4个warp scheduler
		- instruction issue：每个cycle，每个warp scheduler可以选择一个等待执行下一条指令的warp进行执行下一条指令
	- Instruction-level parallelism（ILP）
		- warp执行完一条指令后，执行下一条与上一条不依赖的指令
		- 最常用的是请求内存数据和使用数据分开
	- thread-level parallelism
		- warp scheduler可以从多个候选warp中选择一个执行下一条指令
	- latency hidden
		- latency：一条指令从开始执行到准备执行下一条指令之间的时间
		- **latency被hide了的指标**：如果所有warp scheduler可以在每个cycle总有warp可以issue指令，因此可以看作所有的指令的latency只有1个cycle
		- 4L：绝大多数（除了CC6.0）的device，如果指令满throughput（后面有表，每cycle最多执行某指令的数量），延迟L cycles，则需要4L的指令数量来hide latency
			- **寄存器级别的依赖**：
				- 比如，CC7.x，纯算术指令，下一个指令依赖上一个指令的结果写到寄存器后，才能开始执行，指令通常延迟是L=4 cycles，那么需要16个active warp per multiprocessor（每个cycle选4个warp来issue指令）
				- 如果吞吐量非满，每个cycle能发出的指令数量变少，则需要的active warp变少
				- 如果ILP，warp scheduler可以有更多其他指令直接执行，需要的active warp数量也变少
			- **内存依赖**：
				- 如果涉及到内存，延迟会大幅增加
				- **Arithmetic Intensity:**
					- 不需要内存依赖的算术指令数 / 需要内存依赖的指令数
					- AI越小，需要的warp越多
					- 比如，每进行1次算术运算就需要从片外内存加载1次数据 会比 每进行10次算术运算才需要从片外内存加载1次数据 需要更多的warp来hide latency，保持调度器的忙碌状态
			- 