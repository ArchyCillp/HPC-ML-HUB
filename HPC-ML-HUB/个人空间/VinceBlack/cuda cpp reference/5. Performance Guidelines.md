---
title: 5. Performance Guidelines
---

### 5.1 Overall Performance Optimization Strategies
- 优化讲的是四个基本策略
	- 最大化并行度 以最大化利用好资源
	- 优化内存使用 以最大化内存吞吐量
	- 优化指令使用 以最大化指令吞吐量
	- 减少内存抖动（虚拟内存交换）
- 优化的方向取决于性能瓶颈
	- memory-bound优化指令使用不会带来显著的性能提升
	- 通过profiler看FLOPS和memory吞吐量达到了峰值的多少

### 5.2 Maximize Utilization
- 应用层面
	- 并行的工作给GPU
	- 串行的工作给CPU
	- 用stream和异步操作使host和device能并行工作
	- 数据交流应该尽可能发生在block内部，减少global数据的交流
- multiprocessor层面
	- 指令执行机制
		- 每个multiprocessor有4个warp scheduler
		- instruction issue：每个cycle，每个warp scheduler可以选择一个等待执行下一条指令的warp进行执行下一条指令
	- Instruction-level parallelism（ILP）
		- warp执行完一条指令后，执行下一条与上一条不依赖的指令
		- 最常用的是请求内存数据和使用数据分开
	- thread-level parallelism
		- warp scheduler可以从多个候选warp中选择一个执行下一条指令
	- latency hidden
		- latency：一条指令从开始执行到准备执行下一条指令之间的时间
		- **latency被hide了的指标**：如果所有warp scheduler可以在每个cycle总有warp可以issue指令，因此可以看作所有的指令的latency只有1个cycle
		- 4L：绝大多数（除了CC6.0）的device，如果指令满throughput（后面有instruction throughput表，每cycle最多执行某指令的数量），延迟L cycles，则需要4L的指令数量来hide latency
			- **寄存器级别的依赖**：
				- 比如，CC7.x，纯算术指令，下一个指令依赖上一个指令的结果写到寄存器后，才能开始执行，指令通常延迟是L=4 cycles，那么需要16个active warp per multiprocessor（每个cycle选4个warp来issue指令）
				- 如果吞吐量非满，每个cycle能发出的指令数量变少，则需要的active warp变少
				- 如果ILP，warp scheduler可以有更多其他指令直接执行，需要的active warp数量也变少
			- **内存依赖**：
				- 如果涉及到内存，延迟会大幅增加
				- **Arithmetic Intensity:**
					- 不需要内存依赖的算术指令数 / 需要内存依赖的指令数
					- AI越小，需要的warp越多
					- 比如，每进行1次算术运算就需要从片外内存加载1次数据 会比 每进行10次算术运算才需要从片外内存加载1次数据 需要更多的warp来hide latency，保持调度器的忙碌状态
			- 内存栅栏或同步依赖：
				- 每个SM分配多个block可以减少该类依赖，因为一个block的warp因为同步卡住了可以上另一个block的warp
	- 寄存器数量控制
		- 寄存器全是32bit的
		- maxrregcount
		- __launch_bounds__()
		- __maxnreg__()

### 5.3 Maximize Memory Throughput
- 减少device和host之间的传输
	- 即使串行，也可以考虑把部分host的数据生成代码移到device来以减少device和host的传输
- page-locked host memory
	- 第三章也提到了，这个带宽更大
- mapped memory
	- 提到如果mapped memory是coalesced访问的且只读写一次，则在性能上比显式的copy更优（我还不清楚原理）
- memory transaction
	- 32- 64- 128-byte
	- 分散的warp memory request因为需要更多transaction，降低的是instruction throughput
- global memory 
	- 所有的global读写都会被L2 cache
	- 默认情况下，**只有只读**的global数据会被L1 cache
		- 只读的数据
			- `const __restrict__ int* p`指向的数据肯定是只读的（restrict表示你向编译器保证指向的内存没有被其他指针指向），编译器会尽可能cache这些数据到L1
			- `__ldg()`函数可以用于显式加载只读数据
		- `-Xptas -dlcm=ca` 
			- data load cache mode = cache all
			- 所有global读写都会被L1 cache
			- 当数据访问模式具有较高的局部性时使用
		- `-Xptas -dlcm=cg`
			- 默认
			- data load cache mode = cache global
			- 所有从全局内存读取的数据都会绕过 L1 Cache，直接进入 L2 Cache
			- 当数据访问模式是随机或稀疏时使用
		- 还可以通过直接写ptx来直接要求哪些数据可以被L1 cache
			- `asm("ld.global.ca.f32 %0, [%1];" : "=f"(value) : "l"(input + idx));`
- size & alignment
	- GPU 全局内存访问支持1,2,4,8,16 bytes的word
	- 被访问的数据地址如果自然对齐（可以被其size整除），则只需要一条global memory指令，否则可能需要多条重叠的指令
	- Built-in vector是自然对齐的
	- `struct __align__(16) {float x;float y;float z;};`手动对齐
	- CUDA请求分配的内存地址（比如cudaMalloc）都是至少256-byte对齐的
		- 这一点在自己实现的memory pool时踩过坑，一大块内存自己划分的时候一定要注意对齐的问题
- 2D array
	- 矩阵宽度最好是32（warp）的倍数，否则会有行不能coalesced
	- `cudaMallocPitch()`可以自动适应矩阵宽度，分配的行的长度满足coleasced和内存对齐的需要
- local memory
	- 坏东西，一般是那些你以为是在寄存器里结果是在global memory里的数据
	- 通常包括
		- 不使用常量索引的数组（比如`int a[100]; a[threadIdx.x]=1;`），编译无法获知用了哪个寄存器
		- 寄存器溢出（register spilling），溢出的部分在local memory
	- 如何检查
		- PTX，`ld.local`之类的
		- lmem指标
	- 在global memory中按照 threadID.variableName 的顺序排列，所以一般是coalesced
- shared memory
	- load global -> shared -> syncthreads -> read/write shared -> syncthreads -> write global 
	- 可用shared memory数量（占L1）
		- CC7.0: 96/128KB
		- CC7.5: 64/96KB
		- CC8.0,8.7: 164/192KB
		- CC8.6,8.9: 100/128KB
		- CC9.0: 228/256KB
	- bank conflict
		- **bank conflict是warp内部的概念！！！**
		- Shared memory有32个bank，每个bank的带宽是4byte/cycle
		- 多个线程访问一个bank内不同的数据地址时，指令会被硬件切分成多个顺序的读写
		- 多个线程访问同bank且同地址不会产生bank conflict（会触发广播机制，只有一个thread读，读完了以后广播给要读的其他thread）
		- 避免方法：待更新
### 5.4 Maximize Instruction Throughput

### 5.5 Minimize Memory Thrashing
